{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96cd4fbc",
   "metadata": {},
   "source": [
    "### SimCLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6737818f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42c92a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://zablo.net/blog/post/understanding-implementing-simclr-guide-eli5-pytorch/\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, batch_size, verbose=False, temperature=0.5):\n",
    "        super().__init__()\n",
    "        self.verbose = verbose\n",
    "        self.batch_size = batch_size\n",
    "        self.register_buffer(\"temperature\", torch.tensor(temperature))\n",
    "        self.register_buffer(\"negatives_mask\", (~torch.eye(batch_size * 2, batch_size * 2, dtype=bool)).float())\n",
    "        if self.verbose:\n",
    "            print(f\"negatives_mask: {self.negatives_mask}\")\n",
    "            print(f\"negatives_mask shape: {self.negatives_mask.shape}\")\n",
    "            \n",
    "    def forward(self, emb_i, emb_j):\n",
    "        \"\"\"\n",
    "        emb_i and emb_j are batches of embeddings, where corresponding indices are pairs\n",
    "        z_i, z_j as per SimCLR paper\n",
    "        \"\"\"\n",
    "        z_i = F.normalize(emb_i, dim=1)\n",
    "        z_j = F.normalize(emb_j, dim=1)\n",
    "\n",
    "        representations = torch.cat([z_i, z_j], dim=0)\n",
    "        \n",
    "        similarity_matrix = F.cosine_similarity(representations.unsqueeze(1), representations.unsqueeze(0), dim=2)\n",
    "        \n",
    "        sim_ij = torch.diag(similarity_matrix, self.batch_size)\n",
    "        sim_ji = torch.diag(similarity_matrix, -self.batch_size)\n",
    "        \n",
    "        positives = torch.cat([sim_ij, sim_ji], dim=0)\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"representations: {representations.unsqueeze(1).shape}\")\n",
    "            print(f\"representations: {representations.unsqueeze(0).shape}\")\n",
    "            print(f\"similarity_matrix: {similarity_matrix.shape}\")\n",
    "            print(f\"similarity_matrix: {similarity_matrix}\")\n",
    "            print(f\"sim_ij: {sim_ij}\")\n",
    "            print(f\"sim_ji: {sim_ji}\")\n",
    "            print(f\"positives: {positives.shape}\")\n",
    "        \n",
    "        nominator = torch.exp(positives / self.temperature)\n",
    "        denominator = self.negatives_mask * torch.exp(similarity_matrix / self.temperature)\n",
    "    \n",
    "        loss_partial = -torch.log(nominator / torch.sum(denominator, dim=1))\n",
    "        loss = torch.sum(loss_partial) / (2 * self.batch_size)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "300e7f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "feature_dim = 512\n",
    "emb_1, emb_2 = torch.rand(batch_size, feature_dim), torch.rand(batch_size, feature_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de226d35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negatives_mask: tensor([[0., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 0., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 0., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 0., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0.]])\n",
      "negatives_mask shape: torch.Size([8, 8])\n"
     ]
    }
   ],
   "source": [
    "simclr_loss = ContrastiveLoss(batch_size, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db192b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "representations: torch.Size([8, 1, 512])\n",
      "representations: torch.Size([1, 8, 512])\n",
      "similarity_matrix: torch.Size([8, 8])\n",
      "similarity_matrix: tensor([[1.0000, 0.7604, 0.7783, 0.7217, 0.7632, 0.7457, 0.7285, 0.7567],\n",
      "        [0.7604, 1.0000, 0.7543, 0.7191, 0.7400, 0.7507, 0.7658, 0.7726],\n",
      "        [0.7783, 0.7543, 1.0000, 0.7375, 0.7657, 0.7597, 0.7595, 0.7669],\n",
      "        [0.7217, 0.7191, 0.7375, 1.0000, 0.7286, 0.7354, 0.7313, 0.7466],\n",
      "        [0.7632, 0.7400, 0.7657, 0.7286, 1.0000, 0.7539, 0.7424, 0.7580],\n",
      "        [0.7457, 0.7507, 0.7597, 0.7354, 0.7539, 1.0000, 0.7514, 0.7562],\n",
      "        [0.7285, 0.7658, 0.7595, 0.7313, 0.7424, 0.7514, 1.0000, 0.7578],\n",
      "        [0.7567, 0.7726, 0.7669, 0.7466, 0.7580, 0.7562, 0.7578, 1.0000]])\n",
      "sim_ij: tensor([0.7632, 0.7507, 0.7595, 0.7466])\n",
      "sim_ji: tensor([0.7632, 0.7507, 0.7595, 0.7466])\n",
      "positives: torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "loss = simclr_loss(emb_1, emb_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9762cf1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.9368)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7e859b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/data/denizlab/Users/hh2740/miniconda3/envs/deeplearning_general/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "\n",
    "class SimCLR_Encoder(nn.Module):\n",
    "    def __init__(self, backbone_name, in_dim, out_dim, pretrained=False):\n",
    "        super().__init__()\n",
    "        # simclr backbone\n",
    "        self.simclr_backbone = timm.create_model(backbone_name, pretrained=pretrained)\n",
    "        # simclr projector\n",
    "        in_features = self.simclr_backbone.fc.in_features\n",
    "        self.simclr_backbone.fc = nn.Identity()\n",
    "        self.simclr_projector = nn.Sequential(\n",
    "            nn.Linear(in_features, in_dim, bias=True),\n",
    "            nn.BatchNorm1d(in_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_dim, in_dim, bias=True),\n",
    "            nn.BatchNorm1d(in_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_dim, out_dim, bias=False),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.simclr_backbone(x)\n",
    "        out = self.simclr_projector(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e7899ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimCLR_Encoder('resnet18', 512, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "290cc51d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimCLR_Encoder(\n",
       "  (simclr_backbone): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act1): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "    (fc): Identity()\n",
       "  )\n",
       "  (simclr_projector): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=512, out_features=128, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18a8a7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import requests\n",
    "import gzip\n",
    "import os\n",
    "import numpy as np\n",
    "def download_mnist(url,file_dict=None):\n",
    "    if file_dict is not None:\n",
    "        mnist_data=list()\n",
    "        try:\n",
    "            for i, key in enumerate(file_dict.keys()):    \n",
    "                fname = file_dict[key]\n",
    "                url = os.path.join(url_root,fname)                \n",
    "                isExist = os.path.exists(fname)\n",
    "                if not isExist:\n",
    "                    response = requests.get(url, stream=True)\n",
    "                    fsize=len(response.content)\n",
    "                    print(url)\n",
    "                    with open(fname, 'wb') as fout:\n",
    "                        for data in tqdm(response.iter_content(), desc =fname, total=fsize):\n",
    "                            fout.write(data)\n",
    "                \n",
    "                with gzip.open(fname, \"rb\") as f_in:                \n",
    "                    if fname.find('idx3') != -1:        \n",
    "                        mnist_data.append(np.frombuffer(f_in.read(), np.uint8, offset=16).reshape(-1, 28, 28)) #if images        \n",
    "                    else:                               \n",
    "                        mnist_data.append(np.frombuffer(f_in.read(), np.uint8, offset=8))  #if labels\n",
    "            #return mnist_data in a list format ==> [[train_images], [train_labels], [test_images], [test_labels]] \n",
    "            return mnist_data\n",
    "        except Exception as e:\n",
    "            print(\"Something went wrong:\", e)\n",
    "    else:\n",
    "        print(\"file_dict cannot be None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c533122",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_root = 'http://yann.lecun.com/exdb/mnist'\n",
    "file_dict={\n",
    "    'train_images':'train-images-idx3-ubyte.gz',\n",
    "    'train_labels':'train-labels-idx1-ubyte.gz',\n",
    "    'test_images':'t10k-images-idx3-ubyte.gz',\n",
    "    'test_labels':'t10k-labels-idx1-ubyte.gz'\n",
    "}\n",
    "dataset= download_mnist(url_root,file_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c7728b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images=dataset[0]\n",
    "#train_labels=dataset[1]\n",
    "val_images=dataset[2]\n",
    "#test_labels=dataset[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01fe3e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageOps, ImageFilter, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdc2be59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianBlur(object):\n",
    "    def __init__(self, p, sigma_min, sigma_max):\n",
    "        self.p = p\n",
    "        self.sigma_min, self.sigma_max = sigma_min, sigma_max\n",
    "    def __call__(self, img):\n",
    "        if np.random.rand() < self.p:\n",
    "            sigma = np.random.rand() * (self.sigma_max - self.sigma_min)+ self.sigma_min\n",
    "            return img.filter(ImageFilter.GaussianBlur(sigma))\n",
    "        else:\n",
    "            return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe9ebb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "size = 28\n",
    "data_transform = transforms.Compose([transforms.RandomResizedCrop(size=size),\n",
    "                                     transforms.RandomHorizontalFlip(),\n",
    "                                     transforms.RandomApply(\n",
    "                                         [\n",
    "                                             transforms.ColorJitter(\n",
    "                                                 brightness=(0.6, 1.4), contrast=(0.6, 1.4), saturation=0, hue=0,\n",
    "                                             )\n",
    "                                         ],\n",
    "                                         p=0.8,\n",
    "                                     ),\n",
    "                                     transforms.RandomGrayscale(p=0.2),\n",
    "                                     GaussianBlur(p=1.0, sigma_min=0.1, sigma_max=2.0),\n",
    "                                     transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed565a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MNISTCustomDataset(Dataset):\n",
    "    def __init__(self, images, transform=None, transform_p=None):\n",
    "        self.images = images\n",
    "        self.transform = transform\n",
    "        self.transform_p = transform_p\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.fromarray(self.images[idx]).convert(\"RGB\")\n",
    "        image_1 = self.transform(image)\n",
    "        image_2 = self.transform_p(image)\n",
    "        return image_1, image_2\n",
    "    def __len__(self):\n",
    "        return self.images.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71fd739d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MNISTCustomDataset(train_images, transform=data_transform, transform_p=data_transform)\n",
    "val_dataset = MNISTCustomDataset(val_images, transform=data_transform, transform_p=data_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2208ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size =  64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=2, pin_memory=True,\n",
    "                          shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=2, pin_memory=True,\n",
    "                          shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74400488",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "def train(model, optimizer, criterion, num_epochs, batch_size, train_loader, val_loader):\n",
    "    train_losses, val_losses = [], []\n",
    "    for epoch in trange(num_epochs):\n",
    "        # train model\n",
    "        model.train()\n",
    "        accum_train_loss = 0\n",
    "        for (x_1, x_2) in train_loader:\n",
    "            out_1, out_2 = model(x_1.cuda()).squeeze(), model(x_2.cuda()).squeeze()\n",
    "            loss = criterion(out_1, out_2)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            accum_train_loss += loss.item()\n",
    "        train_losses.append(accum_train_loss / len(train_loader))\n",
    "\n",
    "        # eval model\n",
    "        model.eval()\n",
    "        accum_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                x1, x2 = batch[0], batch[1]\n",
    "                out_1, out_2 = model(x_1.cuda()).squeeze(), model(x_2.cuda()).squeeze()\n",
    "                loss = criterion(out_1, out_2)\n",
    "                accum_val_loss += loss.item()\n",
    "            val_losses.append(accum_val_loss / len(val_loader))\n",
    "            \n",
    "        print(f\"epoch {epoch+1} Train Loss: {accum_train_loss / len(train_loader)}, Validation Loss: {accum_val_loss / len(val_loader)}\")\n",
    "            \n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07f3645e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:37<05:40, 37.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 Train Loss: 4.430632861726694, Validation Loss: 4.167326927185059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 2/10 [01:15<05:01, 37.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 Train Loss: 4.047993498652569, Validation Loss: 3.7923147678375244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 3/10 [01:53<04:24, 37.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 Train Loss: 3.894592859956218, Validation Loss: 3.635878086090088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 4/10 [02:30<03:46, 37.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 Train Loss: 3.791337649366772, Validation Loss: 3.7594809532165527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 5/10 [03:08<03:08, 37.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 Train Loss: 3.7187681450024486, Validation Loss: 3.6511712074279785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 6/10 [03:46<02:30, 37.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 Train Loss: 3.6734036498543037, Validation Loss: 3.6855881214141846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 7/10 [04:23<01:52, 37.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 Train Loss: 3.631831737312716, Validation Loss: 3.5930111408233643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 8/10 [05:01<01:15, 37.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 Train Loss: 3.6076426801203154, Validation Loss: 3.5604779720306396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 9/10 [05:39<00:37, 37.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 Train Loss: 3.5817133818008604, Validation Loss: 3.567700147628784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [06:16<00:00, 37.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 Train Loss: 3.5671773470834838, Validation Loss: 3.5599286556243896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([4.430632861726694,\n",
       "  4.047993498652569,\n",
       "  3.894592859956218,\n",
       "  3.791337649366772,\n",
       "  3.7187681450024486,\n",
       "  3.6734036498543037,\n",
       "  3.631831737312716,\n",
       "  3.6076426801203154,\n",
       "  3.5817133818008604,\n",
       "  3.5671773470834838],\n",
       " [4.167326927185059,\n",
       "  3.7923147678375244,\n",
       "  3.635878086090088,\n",
       "  3.7594809532165527,\n",
       "  3.6511712074279785,\n",
       "  3.6855881214141846,\n",
       "  3.5930111408233643,\n",
       "  3.5604779720306396,\n",
       "  3.567700147628784,\n",
       "  3.5599286556243896])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "model = SimCLR_Encoder('resnet18', 512, 128).cuda()\n",
    "optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "criterion = ContrastiveLoss(batch_size).cuda()\n",
    "num_epochs = 10\n",
    "train(model, optimizer, criterion, num_epochs, batch_size, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce7537c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
